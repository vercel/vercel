name: Unit Tests

on:
  pull_request:

env:
  VERCEL_TELEMETRY_DISABLED: '1'
  TURBO_REMOTE_ONLY: 'true'
  TURBO_TEAM: 'vercel'
  TURBO_TOKEN: ${{ secrets.TURBO_TOKEN }}

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: ${{ github.ref != 'refs/heads/main' }}

jobs:
  setup:
    name: Find Changes
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request'
    outputs:
      tests: ${{ steps['set-tests'].outputs['tests'] }}
      dplUrl: ${{ steps.resolveTarball.outputs.url }}
      affectedPackages: ${{ steps['affected-packages'].outputs['packages'] }}
      testStrategy: ${{ steps['affected-packages'].outputs['strategy'] }}
      affectedCount: ${{ steps['affected-packages'].outputs['count'] }}
      totalCount: ${{ steps['affected-packages'].outputs['total'] }}
      allPackages: ${{ steps['affected-packages'].outputs['allPackages'] }}
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0 # Need full history for turbo query to work
          token: ${{ secrets.GH_TOKEN_PULL_REQUESTS }}
      - uses: actions/setup-node@v4
        with:
          node-version: 22
      - name: install pnpm@8.3.1
        run: npm i -g pnpm@8.3.1
      - run: pnpm install
      - id: affected-packages
        run: |
          # Set base SHA for affected package detection
          export TURBO_BASE_SHA="${{ github.event.pull_request.base.sha }}"

          # Get affected packages info for PR comment
          AFFECTED_OUTPUT=$(node utils/test-affected.js "${{ github.event.pull_request.base.sha }}" 2>&1)

          # Extract affected packages count and total packages count
          PACKAGE_COUNT=$(echo "$AFFECTED_OUTPUT" | grep -o "Found [0-9]* affected packages" | grep -o "[0-9]*" | head -1 || echo "0")
          TOTAL_COUNT=$(echo "$AFFECTED_OUTPUT" | grep -o "Total packages with tests: [0-9]*" | grep -o "[0-9]*" | head -1 || echo "0")

          if echo "$AFFECTED_OUTPUT" | grep -q "config or workflow changes detected"; then
            STRATEGY="all-e2e"
          elif echo "$AFFECTED_OUTPUT" | grep -q "test-all result detected"; then
            STRATEGY="test-all"
          elif [ "$PACKAGE_COUNT" -gt "0" ]; then
            STRATEGY="affected-only"
          else
            STRATEGY="no-tests"
          fi

          # Get the list of affected packages
          PACKAGES=$(echo "$AFFECTED_OUTPUT" | sed -n '/Affected packages that would be tested:/,/This would result in the following turbo filters:/p' | grep "  - " | sed 's/  - //' | tr '\n' ',' | sed 's/,$//')

          # Get all packages (trim whitespace and newlines)
          ALL_PACKAGES=$(echo "$AFFECTED_OUTPUT" | grep "All packages with tests:" | sed 's/All packages with tests: //' | head -1 | xargs)

          # Debug output
          echo "PACKAGE_COUNT=$PACKAGE_COUNT"
          echo "TOTAL_COUNT=$TOTAL_COUNT"
          echo "STRATEGY=$STRATEGY"

          echo "strategy=$STRATEGY" >> $GITHUB_OUTPUT
          echo "packages=$PACKAGES" >> $GITHUB_OUTPUT
          echo "count=$PACKAGE_COUNT" >> $GITHUB_OUTPUT
          echo "total=$TOTAL_COUNT" >> $GITHUB_OUTPUT
          echo "allPackages=$ALL_PACKAGES" >> $GITHUB_OUTPUT
      - id: set-tests
        run: |
          TESTS_ARRAY=$(node utils/chunk-tests.js)
          echo "Unit tests to run:"
          echo "$TESTS_ARRAY"
          echo "tests=$TESTS_ARRAY" >> $GITHUB_OUTPUT
        env:
          TURBO_BASE_SHA: ${{ github.event.pull_request.base.sha }}
          TEST_TYPE: unit
      - uses: patrickedqvist/wait-for-vercel-preview@bfdff514ff78a669f2536e9f4dd4ef5813a704a2
        id: waitForTarball
        continue-on-error: true
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          max_timeout: 360
          check_interval: 5
      - name: Resolve Vercel tarball URL
        id: resolveTarball
        uses: actions/github-script@v7
        env:
          WAIT_URL: ${{ steps.waitForTarball.outputs.url }}
        with:
          script: |
            const owner = context.repo.owner;
            const repo = context.repo.repo;
            const prNumber =
              context.payload.pull_request?.number ?? context.issue.number;

            const waitUrl = process.env.WAIT_URL || '';
            if (waitUrl) {
              core.info(`Using deployment URL from wait step: ${waitUrl}`);
              core.setOutput('url', waitUrl);
              return;
            }

            core.info(
              'No deployment found for the current HEAD commit. Falling back to the most recent successful Vercel preview deployment for this PR.'
            );

            const { data: commits } = await github.rest.pulls.listCommits({
              owner,
              repo,
              pull_number: prNumber,
              per_page: 100,
            });

            // API returns commits oldest->newest; prefer newest first.
            const shas = commits.map(c => c.sha).reverse();

            for (const sha of shas) {
              core.info(`Checking deployments for ${sha}...`);

              const { data: deployments } =
                await github.rest.repos.listDeployments({
                  owner,
                  repo,
                  sha,
                  environment: 'Preview',
                  per_page: 5,
                });

              for (const deployment of deployments) {
                if (deployment.creator?.login !== 'vercel[bot]') {
                  continue;
                }

                const { data: statuses } =
                  await github.rest.repos.listDeploymentStatuses({
                    owner,
                    repo,
                    deployment_id: deployment.id,
                    per_page: 10,
                  });

                const success = statuses.find(
                  s => s.state === 'success' && s.environment_url
                );

                if (success?.environment_url) {
                  core.info(`Resolved deployment URL: ${success.environment_url}`);
                  core.setOutput('url', success.environment_url);
                  return;
                }
              }
            }

            core.setFailed(
              'No Vercel preview deployment found for any commit in this PR.'
            );

  comment-test-strategy:
    name: Comment Test Strategy
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request'
    needs:
      - setup
    steps:
      - name: Comment PR with test strategy
        uses: actions/github-script@v7
        with:
          script: |
            const strategy = '${{ needs.setup.outputs.testStrategy }}';
            const packages = '${{ needs.setup.outputs.affectedPackages }}';
            const allPackages = '${{ needs.setup.outputs.allPackages }}';
            const affectedCount = parseInt('${{ needs.setup.outputs.affectedCount }}') || 0;
            const totalCount = parseInt('${{ needs.setup.outputs.totalCount }}') || 0;
            const baseSha = '${{ github.event.pull_request.base.sha }}';
            const headSha = '${{ github.event.pull_request.head.sha }}';

            // Calculate percentage and unaffected packages
            const percentage = totalCount > 0 ? Math.round((affectedCount / totalCount) * 100) : 0;
            const unaffectedCount = totalCount - affectedCount;
            const unaffectedPercentage = totalCount > 0 ? Math.round((unaffectedCount / totalCount) * 100) : 0;

            // Calculate unaffected package list
            const affectedSet = packages ? new Set(packages.split(',').map(p => p.trim())) : new Set();
            const allPackagesList = allPackages ? allPackages.split(',').map(p => p.trim()) : [];
            const unaffectedPackages = allPackagesList.filter(pkg => !affectedSet.has(pkg));
            const unaffectedList = unaffectedPackages.map(p => `1. \`${p}\``).join('\n');

            let message = '## ðŸ§ª Unit Test Strategy\n\n';
            message += `**Comparing**: [\`${baseSha.substring(0, 7)}\`](https://github.com/${context.repo.owner}/${context.repo.repo}/commit/${baseSha}) â†’ [\`${headSha.substring(0, 7)}\`](https://github.com/${context.repo.owner}/${context.repo.repo}/commit/${headSha}) ([view diff](https://github.com/${context.repo.owner}/${context.repo.repo}/compare/${baseSha}...${headSha}))\n\n`;

            if (strategy === 'all-e2e') {
              message += '**Strategy**: Code changed outside of a package - running all unit tests\n\n';
              message += 'âš ï¸ All unit tests will run because global code changes could impact all packages.\n\n';
              if (packages) {
                const packageList = packages.split(',').map(p => `1. \`${p.trim()}\``).join('\n');
                message += `<details>\n<summary>Affected packages - ${affectedCount} (${percentage}%)</summary>\n\n${packageList}\n\n</details>\n\n`;
              }
              if (unaffectedCount > 0) {
                message += `<details>\n<summary>Unaffected packages - ${unaffectedCount} (${unaffectedPercentage}%)</summary>\n\n${unaffectedList || '_No unaffected packages_'}\n\n</details>\n\n`;
              }
              message += '### Results\n\n';
              message += '- **Unit tests**: All affected packages will run unit tests\n';
              message += '- **E2E tests**: Running in parallel via E2E Tests workflow\n';
              message += '- **Type checks**: All affected packages will run type checks';
            } else if (strategy === 'affected-only') {
              message += '**Strategy**: Affected packages only\n\n';
              message += 'âœ… Only testing packages that have been modified or depend on modified packages.\n\n';
              if (packages) {
                const packageList = packages.split(',').map(p => `1. \`${p.trim()}\``).join('\n');
                message += `<details>\n<summary>Affected packages - ${affectedCount} (${percentage}%)</summary>\n\n${packageList}\n\n</details>\n\n`;
              }
              if (unaffectedCount > 0) {
                message += `<details>\n<summary>Unaffected packages - ${unaffectedCount} (${unaffectedPercentage}%)</summary>\n\n${unaffectedList || '_No unaffected packages_'}\n\n</details>\n\n`;
              }
              message += '### Results\n\n';
              message += '- **Unit tests**: Only affected packages will run unit tests\n';
              message += '- **E2E tests**: Running in parallel via E2E Tests workflow\n';
              message += '- **Type checks**: Only affected packages will run type checks';
            } else if (strategy === 'no-tests') {
              message += '**Strategy**: No tests needed\n\n';
              message += 'âœ¨ No packages affected - skipping tests\n\n';
              message += '### Results\n\n';
              message += '- **Unit tests**: None\n';
              message += '- **E2E tests**: Running in parallel via E2E Tests workflow\n';
              message += '- **Type checks**: None';
            } else if (strategy === 'test-all') {
              message += '**Strategy**: Full unit test suite\n\n';
              message += 'ðŸ”„ Running all unit tests (unable to determine affected packages)\n\n';
              if (packages) {
                const packageList = packages.split(',').map(p => `1. \`${p.trim()}\``).join('\n');
                message += `<details>\n<summary>Affected packages - ${affectedCount} (${percentage}%)</summary>\n\n${packageList}\n\n</details>\n\n`;
              }
              if (unaffectedCount > 0) {
                message += `<details>\n<summary>Unaffected packages - ${unaffectedCount} (${unaffectedPercentage}%)</summary>\n\n${unaffectedList || '_No unaffected packages_'}\n\n</details>\n\n`;
              }
              message += '### Results\n\n';
              message += '- **Unit tests**: All packages will run unit tests\n';
              message += '- **E2E tests**: Running in parallel via E2E Tests workflow\n';
              message += '- **Type checks**: All packages will run type checks';
            } else {
              message += '**Strategy**: Unknown\n\n';
              message += `âš ï¸ Unknown strategy: ${strategy}\n\n`;
              message += '### Results\n\n';
              message += '- **Unit tests**: Unknown\n';
              message += '- **E2E tests**: Running in parallel via E2E Tests workflow\n';
              message += '- **Type checks**: Unknown';
            }

            message += '\n\n---\n*This comment is automatically generated based on the [affected testing strategy](.github/AFFECTED_TESTING.md)*';

            // Find existing comment to update
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
            });

            const existingComment = comments.find(comment =>
              comment.user.login === 'github-actions[bot]' &&
              (comment.body.includes('## ðŸ§ª Unit Test Strategy') || comment.body.includes('## ðŸ§ª Test Strategy'))
            );

            if (existingComment) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: existingComment.id,
                body: message
              });
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: message
              });
            }

  test:
    timeout-minutes: 120
    runs-on: ${{ matrix.runner }}
    name: ${{matrix.scriptName}} (${{matrix.packageName}}, ${{matrix.chunkNumber}}, ${{ matrix.runner }}, Node v${{ matrix.nodeVersion }})
    if: ${{ needs.setup.outputs['tests'] != '[]' }}
    needs:
      - setup
    strategy:
      fail-fast: false
      matrix:
        include: ${{ fromJson(needs.setup.outputs['tests']) }}
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0 # Need full history for turbo query to work
      - uses: actions/setup-node@v4
        with:
          node-version: ${{ matrix.nodeVersion }}

      - name: Setup Rust toolchain
        uses: dtolnay/rust-toolchain@f7ccc83f9ed1e5b9c81d8a67d7ad1a747e22a561 # 2025-12-16
        with:
          toolchain: stable
          targets: wasm32-wasip2

      # yarn 1.22.21 introduced a Corepack bug when running tests.
      # this can be removed once https://github.com/yarnpkg/yarn/issues/9015 is resolved
      - name: install yarn@1.22.19
        run: npm i -g yarn@1.22.19

      - name: install pnpm@8.3.1
        run: npm i -g pnpm@8.3.1

      - run: pnpm install

      - name: Build ${{matrix.packageName}} and all its dependencies
        run: node utils/gen.js && node_modules/.bin/turbo run build --cache-dir=".turbo" --log-order=stream --filter=${{matrix.packageName}}...
        env:
          FORCE_COLOR: '1'
      - name: Test ${{matrix.packageName}}
        run: node utils/gen.js && node_modules/.bin/turbo run ${{matrix.testScript}} --summarize --cache-dir=".turbo" --log-order=stream --filter=${{matrix.packageName}} -- ${{ join(matrix.testPaths, ' ') }}
        shell: bash
        env:
          JEST_JUNIT_OUTPUT_FILE: ${{github.workspace}}/.junit-reports/${{matrix.scriptName}}-${{matrix.packageName}}-${{matrix.chunkNumber}}-${{ matrix.runner }}.xml
          VERCEL_CLI_VERSION: ${{ needs.setup.outputs.dplUrl }}/tarballs/vercel.tgz
          VERCEL_TOKEN: ${{ secrets.VERCEL_TOKEN }}
          VERCEL_TEAM_ID: ${{ secrets.VERCEL_TEAM_ID }}
          TURBO_BASE_SHA: ${{ github.event.pull_request.base.sha }}
          FORCE_COLOR: '1'
      - name: 'Determine Turbo HIT or MISS'
        if: ${{ !cancelled() }}
        id: turbo-summary
        shell: bash
        run: |
          TURBO_MISS_COUNT=`node utils/determine-turbo-hit-or-miss.js`
          echo "MISS COUNT: $TURBO_MISS_COUNT"
          echo "misses=$TURBO_MISS_COUNT" >> $GITHUB_OUTPUT
      - name: 'Upload Test Report to Datadog'
        if: ${{ steps['turbo-summary'].outputs.misses != '0' && !cancelled() }}
        run: 'pnpm dlx @datadog/datadog-ci@4.2.2 junit upload --service vercel-cli .junit-reports'
        env:
          DATADOG_API_KEY: ${{secrets.DATADOG_API_KEY_CLI}}
          DD_ENV: ci

  summary:
    name: Summary
    runs-on: ubuntu-latest
    timeout-minutes: 5
    if: always()
    needs:
      - test
    steps:
      - name: Check All
        run: |-
          for status in ${{ join(needs.*.result, ' ') }}
          do
            if [ "$status" != "success" ] && [ "$status" != "skipped" ]
            then
              echo "Some checks failed"
              exit 1
            fi
          done
